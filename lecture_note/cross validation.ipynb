{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차검증(Cross validation)을 통한 모델 평가\n",
    "[University of Turku](<https://www.utu.fi/fi>)의 Data Analysis and Knowledge Discovery 강의 내용을 정리한 노트이며, 개인적인 의견과 자료조사를 더했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차검증은 왜 필요할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝 모델의 [평가 단계](https://euneestella.github.io/data%20analysis%20and%20knowledge%20discovery/2019/11/17/CRISP-DM/)에는 모델이 적절한지 검증하는 과정이 포함되어 있다. 보통은 학습 데이터(training set)과 평가 데이터(test set)를 나눈 다음, 평가 데이터로 학습 데이터를 검증하는데 이 방법에는 한계가 있다. \n",
    "\n",
    "만약 <u>평가 데이터가 너무 작은 경우</u> 검증 결과의 분산이 커지게 된다는 점이다. 운이 좋으면 검증에 문제가 없고, 운이 나쁘면 검증 과정에서 탈락하는 식. 이런 우연에 따른 검증 결과의 왜곡을 방지하기 위해 교차검증이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-one-out 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가능한 한 많은 데이터를 학습 데이터로 사용하고 싶다. 가능한 패턴을 찾고 싶기 때문!\n",
    "- 가능한 한 많은 데이터를 평가 데이터로 사용하고 싶다. 오류를 정확히 탐지하고 싶기 때문!\n",
    "\n",
    "이를 해결하기 위해 <u>모든 데이터가 적어도 한번씩은 테스트 데이터로 쓰이게</u> 한다. 교차검증의 기본 알고리즘은 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i=1 to n do :\n",
    "    i번째 instance를 제외하고 모델 학습\n",
    "    i번째 instance에 모델을 적용하고 결과를 예측\n",
    "참값과 예측된 결과 사이의 에러 계산\n",
    "모든 데이터에 대해 최종 모델을 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://github.com/euneestella/utu_data_analysis/blob/master/lecture_note/img/leave-one-out.PNG?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 데이터를 학습 데이터와 평가 데이터로 사용할 수 있다. 그러나 매 반복마다 학습 데이터에 사용된 데이터가 평가 데이터로 사용되지 않으므로 <u>과대적합(overfitting)</u>이 발생하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교차검증 결과 가장 적은 leave one out error를 가진 모델을 선정한다. 그러나 100% 완벽한 방법은 아니며, 고비용의 계산이 필요하다는 단점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>큰 데이터셋의 경우</u> 계산 작업량이 매우 많기 때문에 leave one out 교차검증을 사용하기 어렵다. 따라서 비슷한 아이디어에서 출발하는 K-fold 교차검증을 사용한다.\n",
    "\n",
    "leave one out과 다른 점은 한 개씩의 데이터를 제외하고 모델을 학습하는 것이 아니라 <u>K개의 집합</u>으로 데이터를 나눈 다음 교차검증을 수행하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://github.com/euneestella/utu_data_analysis/blob/master/lecture_note/img/k-fold.PNG?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림의 경우는 K=4인 경우로, 데이터를 4개의 부분으로 나눈 다음 4번의 반복 교차검증을 수행한다. K가 의미하는 것이 'K개씩 묶는다'가 아니라 'K개의 부분으로 나눈다'임에 유의해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold 교차검증은 leave one out 교차검증 방법보다 계산 비용이 적다. 물론 fold에 따라 분산의 문제가 있을 수 있다는 단점이 있다. K-fold에는 <b>층화</b>를 이용한 방법(stratified K-fold cross-validation)과 <b>M번 반복</b>하는 방법(M-times repeated K-fold cross-validation), <b>중첩</b>하는 방법(nested K-fold cross validation)이 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
