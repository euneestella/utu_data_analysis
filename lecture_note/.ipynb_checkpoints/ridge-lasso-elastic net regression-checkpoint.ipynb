{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀분석과 다중공선성\n",
    "[University of Turku](<https://www.utu.fi/fi>)의 Data Analysis and Knowledge Discovery 강의 내용을 정리한 노트이며, 개인적인 의견과 자료조사를 더했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중공선성(Multicollinearity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다중공선성은 회귀분석을 할 때, <u>독립변수 사이에 높은 선형관계</u>가 나타나는 경우이다. 다중공선성을 띄는 데이터에 대해 일반적인 방식의 단순 선형 회귀 모형을 만들면 R-square값이 높아 회귀식의 설명력은 높지만, P-value 값이 커지기 때문에 <u>회귀 계수의 영향력이 과다 추정</u>된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규화(Regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규화는 다중공선성의 문제를 해결하기 위한 대표적인 방법이다. 다음의 회귀분석 방법들은 다중공선성의 문제를 정규화를 통해 해결한 방법들이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 릿지 회귀(Ridge regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "릿지 회귀는 '정규화된 최소제곱법(regularized least-square)'이라고 부르기도 한다. 기본적인 아이디어는 단순 선형 회귀처럼 학습 데이터의 평균제곱오차(MSE)를 줄이되, 다중공선성 문제를 해결하기 위해 <u>회귀 계수의 제곱합</u>을 계산해 더하는 방식이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\underset { w }{ argmin } \\left\\{ \\sum _{ i=1 }^{ n }{ { \\left( { w }^{ T }{ x }_{ i }-{ y }_{ i } \\right)  }^{ 2 }+\\lambda \\sum _{ i=0 }^{ d }{ w_{ i }^{ 2 } }  }  \\right\\}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\lambda \\sum _{ i=0 }^{ d }{ w_{ i }^{ 2 } }  $ 부분이 정규화의 핵심(regularizer)으로, <u>회귀계수가 너무 커지지 않게끔</u> 규제(penalty)를 한다. 특히 고차원의 데이터를 다룰 때 단순 선형 회귀 모형보다 더 robust하다는 장점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬에서는 ```sklearn.linear_model.Ridge```로 불러온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라쏘 회귀(Lasso regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라쏘 회귀는 릿지 회귀와 유사하나, <u>회귀 계수의 절댓값</u>을 계산해 더하는 방식이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\underset { w }{ argmin } \\left\\{ \\sum _{ i=1 }^{ n }{ { \\left( { w }^{ T }{ x }_{ i }-{ y }_{ i } \\right)  }^{ 2 }+\\lambda \\sum _{ i=0 }^{ d }{ \\left| w_{ i } \\right|  }  }  \\right\\}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 $𝜆$가 커지면 계수 ${ w }_{ i }$가 0에 가까워지는데, 영향력이 적은 변수의 계수를 0으로 만들기 때문에 변수 선택 알고리즘(feature select algorithm)으로 자주 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬에서는 ```sklearn.linear_model.Lasso```로 불러온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 엘라스틱넷(Elastic net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "릿지 회귀와 라쏘 회귀 기법을 더한 방식으로, 회귀 계수의 <u>제곱합과 절댓값 모두</u>를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\underset { w }{ argmin } \\left\\{ \\sum _{ i=1 }^{ n }{ { \\left( { w }^{ T }{ x }_{ i }-{ y }_{ i } \\right)  }^{ 2 }+{ { \\lambda  }_{ 1 }\\sum _{ i=0 }^{ d }{ \\left| { w }_{ i } \\right|  } +{ \\lambda  }_{ 2 } }\\sum _{ i=0 }^{ d }{ w_{ i }^{ 2 } }  }  \\right\\}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "릿지 회귀와 라쏘 회귀의 정규화 정도가 다르기 때문에 둘을 적절히 조절한 방식이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬에서는 ```sklearn.linear_model.ElasticNet```으로 불러온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 서포트 벡터 회귀(Support vector regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\underset { w }{ argmin } \\left\\{ \\sum _{ i=1 }^{ n }{ max\\left( 0,\\quad \\left| { w }^{ T }{ x }_{ i }-{ y }_{ i } \\right| -\\epsilon  \\right) \\sum _{ i=0 }^{ d }{ w_{ i }^{ 2 } }  }  \\right\\}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자료에 있는 outlier들에 대해 더욱 robust하며, 파이썬에서는 ```sklearn.svm.SVR```로 불러온다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
